{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import helper\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "def showImageSample():\n",
    "    show_n_images = 25\n",
    "    data_dir = './labeled/'\n",
    "    glob_obj = glob(os.path.join(data_dir, '0','*.jpeg'))\n",
    "    digitals_image = helper.get_batch(glob_obj[:show_n_images], 28, 28, 'L')\n",
    "    pyplot.imshow(helper.images_square_grid(digitals_image, 'L'), cmap='gray')\n",
    "#showImageSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \n",
    "    x = tf.placeholder(dtype=tf.float32,shape=(None,image_width,image_height,image_channels),name=\"inputs_x\")\n",
    "    z = tf.placeholder(dtype=tf.float32,shape=(None,z_dim),name=\"z_dim\")\n",
    "    learning_rate = tf.placeholder(dtype=tf.float32,shape=(),name=\"learning_rate\")\n",
    "\n",
    "    return x, z, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "\n",
    "    alpha=0.2\n",
    "    with tf.variable_scope(\"discriminator\",reuse=reuse):\n",
    "        conv_1 = tf.layers.conv2d(images, 64, 4, strides=2, padding='same')\n",
    "        conv_1_bn = tf.layers.batch_normalization(conv_1, training=True)\n",
    "        relu1 = tf.maximum(alpha * conv_1_bn, conv_1_bn)\n",
    "        # 14x14x64\n",
    "        \n",
    "        conv_2 = tf.layers.conv2d(relu1, 128, 4, strides=2, padding='same')\n",
    "        conv_2_bn = tf.layers.batch_normalization(conv_2, training=True)\n",
    "        relu2 = tf.maximum(alpha * conv_2_bn, conv_2_bn)\n",
    "        # 7x7x128\n",
    "        \n",
    "        conv_3 = tf.layers.conv2d(relu2, 256, 4, strides=2, padding='same')\n",
    "        conv_3_bn = tf.layers.batch_normalization(conv_3, training=True)\n",
    "        relu3 = tf.maximum(alpha * conv_3_bn, conv_3_bn)\n",
    "        # 4x4x256\n",
    "\n",
    "        flat = tf.reshape(relu3, (-1, 4*4*256))\n",
    "        logits = tf.layers.dense(flat, 1)\n",
    "        out = tf.sigmoid(logits)\n",
    "\n",
    "    return out, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim=5 , is_train=True):\n",
    "    alpha=0.2\n",
    "    with tf.variable_scope('generator',reuse=not(is_train)):\n",
    "        # Reshape it to start the convolutional stack\n",
    "        fc = tf.layers.dense(z, 4*4*512)\n",
    "        \n",
    "        x = tf.reshape(fc, (-1, 4, 4, 512))\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        relu_x = tf.maximum(alpha * x, x)\n",
    "        # 4x4x512 now\n",
    "\n",
    "        #conv2d_1_t = tf.nn.conv2d_transpose(relu_x, kernel, output_shape=[64,7,7,256], strides=[1,2,2,1], padding='SAME')\n",
    "        conv2d_1_t = tf.layers.conv2d_transpose(relu_x, 256,4, strides=1, padding='valid')\n",
    "        conv2d_1_t_bn = tf.layers.batch_normalization(conv2d_1_t, training=is_train)\n",
    "        relu1 = tf.maximum(alpha * conv2d_1_t_bn, conv2d_1_t_bn)\n",
    "        # 7x7x256 now\n",
    "        \n",
    "        conv2d_2_t = tf.layers.conv2d_transpose(relu1, 128, 4, strides=2, padding='same')\n",
    "        conv2d_2_t_bn = tf.layers.batch_normalization(conv2d_2_t, training=is_train)\n",
    "        relu2 = tf.maximum(alpha * conv2d_2_t_bn, conv2d_2_t_bn)\n",
    "        # 14x14x128\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(relu2, out_channel_dim, 4, strides=2, padding='same')\n",
    "        # 28x28x3 now\n",
    "        out = tf.tanh(logits)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim):\n",
    "    # TODO: Implement Function\n",
    "    g_model = generator(input_z, out_channel_dim)\n",
    "    d_model_real, d_logits_real = discriminator(input_real)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
    "\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)*(1 - 0.1)))\n",
    "    \n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        \n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode):\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.normal(0, 0.02, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "    print(samples.shape)\n",
    "    images_grid = helper.images_square_grid(samples, image_mode)\n",
    "    pyplot.imshow(images_grid, cmap=cmap)\n",
    "    pyplot.show()\n",
    "    \n",
    "    \n",
    "def save_output(sess, n_images, input_z, out_channel_dim, image_mode, path, prefix):\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.normal(0, 0.02, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "    \n",
    "    helper.save_images(samples, image_mode,path,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape, data_image_mode,output_path,output_prefix):\n",
    "\n",
    "    input_real,input_z, lr = model_inputs(*data_shape[1:], z_dim)\n",
    "    \n",
    "    out_channel_dim = 1\n",
    "    if data_image_mode == \"RGB\" : \n",
    "        out_channel_dim = 3\n",
    "    d_loss, g_loss = model_loss(input_real,input_z,out_channel_dim)\n",
    "    d_train_opt, g_train_opt = model_opt(d_loss,g_loss,lr,beta1)\n",
    "\n",
    "    steps = 0\n",
    "    start = time.clock()\n",
    "    totoal_start = start\n",
    "    generate_number = 0\n",
    "    config = tf.ConfigProto() \n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "    \n",
    "    with tf.Session(config = config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        patience = 10\n",
    "        for epoch_i in range(epoch_count):\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                # TODO: Train Model\n",
    "                steps += 1\n",
    "\n",
    "                batch_images = batch_images * 2\n",
    "                batch_z = np.random.normal(0, 0.02,  size=(batch_size, z_dim))\n",
    "                _ = sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z, lr :learning_rate})\n",
    "                _ = sess.run(g_train_opt, feed_dict={input_real: batch_images, input_z: batch_z, lr :learning_rate})\n",
    "                if steps % 100 == 0 :\n",
    "                    end = time.clock()\n",
    "                    train_loss_d = d_loss.eval({input_real: batch_images, input_z: batch_z})\n",
    "                    train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "                    print(\"Time: {:.4f}s ..Epoch {}/{}.setp:{}...\".format((end - start),epoch_i+1, epoch_count,steps),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}...\".format(train_loss_g),\n",
    "                          \"patience: {:2d}\".format(patience))\n",
    "                    start = time.clock()\n",
    "                    if steps > 5000 and train_loss_g < train_loss_d and epoch_i > 5:\n",
    "                        patience = patience - 1\n",
    "                        if (patience == 0):\n",
    "                            for i in range(int(20000/100)):\n",
    "                                save_output(sess,100,input_z,out_channel_dim,data_image_mode,output_path,output_prefix)\n",
    "                            return\n",
    "                    else:\n",
    "                        patience = 10\n",
    "                if steps % 100 == 0:\n",
    "                    show_generator_output(sess,4,input_z,out_channel_dim,data_image_mode)\n",
    "                    \n",
    "                if int(time.clock() - totoal_start) > 1800:\n",
    "                    for i in range(20000/100):\n",
    "                        save_output(sess,100,input_z,out_channel_dim,data_image_mode,output_path,output_prefix)\n",
    "                    \n",
    "        show_generator_output(sess,4,input_z,out_channel_dim,data_image_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_dir = './labeled/'\n",
    "    batch_size = 128\n",
    "    z_dim = 100\n",
    "    learning_rate = 0.002\n",
    "    beta1 = 0.5\n",
    "    epochs = 20000\n",
    "    \n",
    "    output_path = './gen'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    # for every subdir gen the fake image\n",
    "    for output_prefix in sorted(os.listdir(data_dir)):\n",
    "        print('begin : ',output_prefix)\n",
    "        output_dir_path=os.path.join(output_path,output_prefix)\n",
    "\n",
    "        if not os.path.exists(output_dir_path):\n",
    "            os.mkdir(output_dir_path)\n",
    "\n",
    "        digitals_dataset = helper.Dataset('resized', glob(os.path.join(data_dir, output_prefix+'/*.jpeg')))\n",
    "        with tf.Graph().as_default():\n",
    "            train(epochs, batch_size, z_dim, learning_rate, beta1, digitals_dataset.get_batches,\n",
    "                  digitals_dataset.shape, digitals_dataset.image_mode,output_dir_path,output_prefix)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
